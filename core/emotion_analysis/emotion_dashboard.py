"""
Emotion Analysis Dashboard Module

Provides Streamlit UI for emotion analysis and consistency checking.
"""

import json
from datetime import datetime
from typing import List, Dict, Any, Optional

try:
    import streamlit as st
    import plotly.express as px
    import plotly.graph_objects as go
    import pandas as pd
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

from .emotion_analyzer import EmotionAnalyzer
from .consistency_checker import ConsistencyChecker
from .emotion_detector import EmotionLabel

class EmotionAnalysisDashboard:
    """Streamlit dashboard for emotion analysis."""
    
    def __init__(self):
        if not STREAMLIT_AVAILABLE:
            raise ImportError("Streamlit and plotting libraries are required for the emotion analysis dashboard")
        
        self.analyzer = EmotionAnalyzer()
        self.checker = ConsistencyChecker()
    
    def render_dashboard(self, project_id: str):
        """Render the complete emotion analysis dashboard."""
        
        st.title("ğŸ­ æƒ…æ„Ÿåˆ†æå’Œä¸€è‡´æ€§æ£€æŸ¥")
        
        if not project_id:
            st.warning("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªé¡¹ç›®")
            return
        
        # Main tabs
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“Š æƒ…æ„Ÿæ¦‚è§ˆ",
            "ğŸ” è¯¦ç»†åˆ†æ", 
            "âš–ï¸ ä¸€è‡´æ€§æ£€æŸ¥",
            "ğŸ“ˆ æƒ…æ„Ÿè¶‹åŠ¿"
        ])
        
        with tab1:
            self._render_emotion_overview(project_id)
        
        with tab2:
            self._render_detailed_analysis(project_id)
        
        with tab3:
            self._render_consistency_check(project_id)
        
        with tab4:
            self._render_emotion_trends(project_id)
    
    def _render_emotion_overview(self, project_id: str):
        """Render emotion overview tab."""
        st.subheader("ğŸ“Š é¡¹ç›®æƒ…æ„Ÿæ¦‚è§ˆ")
        
        # Get project emotion summary
        summary = self.analyzer.get_project_emotion_summary(project_id)
        
        if summary["total_analyses"] == 0:
            st.info("è¯¥é¡¹ç›®è¿˜æ²¡æœ‰è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
            
            # Option to run new analysis
            if st.button("ğŸ­ å¼€å§‹æƒ…æ„Ÿåˆ†æ"):
                self._run_new_analysis(project_id)
            return
        
        # Display summary metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("åˆ†ææ¬¡æ•°", summary["total_analyses"])
        
        with col2:
            latest_consistency = summary.get("latest_consistency")
            if latest_consistency is not None:
                st.metric("æœ€æ–°ä¸€è‡´æ€§", f"{latest_consistency:.2f}")
            else:
                st.metric("æœ€æ–°ä¸€è‡´æ€§", "N/A")
        
        with col3:
            avg_consistency = summary.get("average_consistency")
            if avg_consistency is not None:
                st.metric("å¹³å‡ä¸€è‡´æ€§", f"{avg_consistency:.2f}")
            else:
                st.metric("å¹³å‡ä¸€è‡´æ€§", "N/A")
        
        with col4:
            trend = summary.get("improvement_trend", "stable")
            trend_icon = {"improving": "ğŸ“ˆ", "declining": "ğŸ“‰", "stable": "â¡ï¸"}[trend]
            st.metric("è¶‹åŠ¿", f"{trend_icon} {trend}")
        
        # List recent analyses
        st.subheader("ğŸ“‹ åˆ†æå†å²")
        
        analyses = self.analyzer.list_project_analyses(project_id)
        
        if analyses:
            analysis_data = []
            for analysis in analyses[:10]:  # Show last 10
                analysis_data.append({
                    "åˆ†æID": analysis["analysis_id"][-8:],
                    "åˆ›å»ºæ—¶é—´": analysis["created_at"][:19],
                    "ä¸€è‡´æ€§è¯„åˆ†": f"{analysis['overall_consistency']:.2f}",
                    "ç‰‡æ®µæ•°é‡": analysis["segments_count"],
                    "è´¨é‡é—®é¢˜": analysis["quality_issues_count"]
                })
            
            df = pd.DataFrame(analysis_data)
            st.dataframe(df, use_container_width=True)
            
            # Quick analysis option
            selected_analysis = st.selectbox(
                "é€‰æ‹©åˆ†ææŸ¥çœ‹è¯¦æƒ…",
                analyses,
                format_func=lambda x: f"{x['analysis_id'][-8:]} - {x['created_at'][:19]}"
            )
            
            if st.button("ğŸ“Š æŸ¥çœ‹è¯¦ç»†åˆ†æ"):
                st.session_state.selected_analysis_id = selected_analysis["analysis_id"]
                st.rerun()
        
        # New analysis section
        st.subheader("â• æ–°å»ºåˆ†æ")
        
        if st.button("ğŸ­ è¿è¡Œæ–°çš„æƒ…æ„Ÿåˆ†æ"):
            self._run_new_analysis(project_id)
    
    def _render_detailed_analysis(self, project_id: str):
        """Render detailed analysis tab."""
        st.subheader("ğŸ” è¯¦ç»†æƒ…æ„Ÿåˆ†æ")
        
        # Check if analysis is selected
        selected_analysis_id = st.session_state.get("selected_analysis_id")
        
        if not selected_analysis_id:
            st.info("è¯·å…ˆåœ¨æƒ…æ„Ÿæ¦‚è§ˆä¸­é€‰æ‹©ä¸€ä¸ªåˆ†æ")
            return
        
        # Load analysis
        analysis = self.analyzer.load_analysis(selected_analysis_id)
        if not analysis:
            st.error("æ— æ³•åŠ è½½é€‰å®šçš„åˆ†æ")
            return
        
        # Analysis summary
        st.subheader(f"ğŸ“‹ åˆ†ææ‘˜è¦ - {selected_analysis_id[-8:]}")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»ä½“ä¸€è‡´æ€§", f"{analysis.overall_consistency:.2f}")
        
        with col2:
            st.metric("åˆ†æç‰‡æ®µæ•°", len(analysis.segments))
        
        with col3:
            st.metric("è´¨é‡é—®é¢˜æ•°", len(analysis.quality_issues))
        
        with col4:
            st.metric("è¯­è¨€å¯¹", f"{analysis.source_language} â†’ {analysis.target_language}")
        
        # Emotion distribution
        st.subheader("ğŸ“Š æƒ…æ„Ÿåˆ†å¸ƒ")
        
        if analysis.emotion_distribution:
            # Create pie chart
            emotions = list(analysis.emotion_distribution.keys())
            counts = list(analysis.emotion_distribution.values())
            
            fig = px.pie(
                values=counts,
                names=emotions,
                title="åŸæ–‡æƒ…æ„Ÿåˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Segment details
        st.subheader("ğŸ“ ç‰‡æ®µè¯¦æƒ…")
        
        # Filter options
        col1, col2 = st.columns(2)
        
        with col1:
            filter_emotion = st.selectbox(
                "æŒ‰æƒ…æ„Ÿç­›é€‰",
                ["å…¨éƒ¨"] + [emotion.value for emotion in EmotionLabel]
            )
        
        with col2:
            filter_issues = st.selectbox(
                "æŒ‰é—®é¢˜ç­›é€‰",
                ["å…¨éƒ¨", "æœ‰é—®é¢˜", "æ— é—®é¢˜"]
            )
        
        # Filter segments
        filtered_segments = analysis.segments
        
        if filter_emotion != "å…¨éƒ¨":
            filtered_segments = [
                seg for seg in filtered_segments 
                if seg.original_emotion.primary_emotion.emotion.value == filter_emotion
            ]
        
        if filter_issues == "æœ‰é—®é¢˜":
            filtered_segments = [seg for seg in filtered_segments if seg.consistency_issues]
        elif filter_issues == "æ— é—®é¢˜":
            filtered_segments = [seg for seg in filtered_segments if not seg.consistency_issues]
        
        # Display segments
        for i, segment in enumerate(filtered_segments[:20]):  # Show first 20
            with st.expander(f"ç‰‡æ®µ {segment.segment_id} - {segment.original_emotion.primary_emotion.emotion.value}"):
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**åŸæ–‡:**")
                    st.write(segment.original_text)
                    st.write(f"**æƒ…æ„Ÿ:** {segment.original_emotion.primary_emotion.emotion.value}")
                    st.write(f"**æƒ…æ„Ÿå¼ºåº¦:** {segment.original_emotion.primary_emotion.intensity:.2f}")
                    st.write(f"**æ•´ä½“æƒ…æ„Ÿ:** {segment.original_emotion.overall_sentiment}")
                
                with col2:
                    st.write("**è¯‘æ–‡:**")
                    st.write(segment.translated_text)
                    st.write(f"**æƒ…æ„Ÿ:** {segment.translated_emotion.primary_emotion.emotion.value}")
                    st.write(f"**æƒ…æ„Ÿå¼ºåº¦:** {segment.translated_emotion.primary_emotion.intensity:.2f}")
                    st.write(f"**æ•´ä½“æƒ…æ„Ÿ:** {segment.translated_emotion.overall_sentiment}")
                
                # Emotion match score
                st.write(f"**æƒ…æ„ŸåŒ¹é…åº¦:** {segment.emotion_match_score:.2f}")
                
                # Issues and recommendations
                if segment.consistency_issues:
                    st.write("**ä¸€è‡´æ€§é—®é¢˜:**")
                    for issue in segment.consistency_issues:
                        st.write(f"- {issue}")
                
                if segment.recommendations:
                    st.write("**å»ºè®®:**")
                    for rec in segment.recommendations:
                        st.write(f"- {rec}")
        
        # Overall recommendations
        if analysis.recommendations:
            st.subheader("ğŸ’¡ æ•´ä½“å»ºè®®")
            for rec in analysis.recommendations:
                st.write(f"- {rec}")
    
    def _render_consistency_check(self, project_id: str):
        """Render consistency check tab."""
        st.subheader("âš–ï¸ æƒ…æ„Ÿä¸€è‡´æ€§æ£€æŸ¥")
        
        # Get latest analysis
        analyses = self.analyzer.list_project_analyses(project_id)
        
        if not analyses:
            st.info("è¯·å…ˆè¿è¡Œæƒ…æ„Ÿåˆ†æ")
            return
        
        latest_analysis = self.analyzer.load_analysis(analyses[0]["analysis_id"])
        if not latest_analysis:
            st.error("æ— æ³•åŠ è½½æœ€æ–°åˆ†æ")
            return
        
        # Run consistency check
        if st.button("ğŸ” è¿è¡Œä¸€è‡´æ€§æ£€æŸ¥"):
            with st.spinner("æ­£åœ¨è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥..."):
                consistency_report = self.checker.check_project_consistency(latest_analysis)
                st.session_state.consistency_report = consistency_report
        
        # Display consistency report
        if "consistency_report" in st.session_state:
            report = st.session_state.consistency_report
            
            # Overall score
            st.subheader("ğŸ“Š ä¸€è‡´æ€§è¯„åˆ†")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                score_color = "green" if report.overall_score > 0.7 else "orange" if report.overall_score > 0.4 else "red"
                st.markdown(f"<h2 style='color: {score_color}'>{report.overall_score:.2f}</h2>", unsafe_allow_html=True)
                st.write("æ€»ä½“ä¸€è‡´æ€§è¯„åˆ†")
            
            with col2:
                st.metric("æ€»é—®é¢˜æ•°", len(report.issues))
            
            with col3:
                critical_issues = len([issue for issue in report.issues if issue.severity == "critical"])
                st.metric("ä¸¥é‡é—®é¢˜", critical_issues)
            
            # Quality metrics
            st.subheader("ğŸ“ˆ è´¨é‡æŒ‡æ ‡")
            
            metrics = report.quality_metrics
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æƒ…æ„ŸåŒ¹é…ç‡", f"{metrics.get('emotion_match_rate', 0):.2%}")
            
            with col2:
                st.metric("æƒ…æ„ŸåŒ¹é…ç‡", f"{metrics.get('sentiment_match_rate', 0):.2%}")
            
            with col3:
                st.metric("é—®é¢˜ç‰‡æ®µç‡", f"{metrics.get('segments_with_issues_rate', 0):.2%}")
            
            with col4:
                st.metric("ä¿¡å¿ƒåº¦ä¸‹é™", f"{metrics.get('confidence_drop', 0):.2f}")
            
            # Issues breakdown
            if report.issues:
                st.subheader("âš ï¸ ä¸€è‡´æ€§é—®é¢˜")
                
                # Group issues by severity
                issues_by_severity = {}
                for issue in report.issues:
                    if issue.severity not in issues_by_severity:
                        issues_by_severity[issue.severity] = []
                    issues_by_severity[issue.severity].append(issue)
                
                # Display issues by severity
                severity_order = ["critical", "high", "medium", "low"]
                severity_colors = {
                    "critical": "ğŸ”´",
                    "high": "ğŸŸ ", 
                    "medium": "ğŸŸ¡",
                    "low": "ğŸŸ¢"
                }
                
                for severity in severity_order:
                    if severity in issues_by_severity:
                        st.write(f"**{severity_colors[severity]} {severity.upper()} é—®é¢˜:**")
                        
                        for issue in issues_by_severity[severity]:
                            with st.expander(f"{issue.issue_type} - ç½®ä¿¡åº¦: {issue.confidence:.2f}"):
                                st.write(f"**æè¿°:** {issue.description}")
                                st.write(f"**å½±å“ç‰‡æ®µ:** {len(issue.segment_ids)} ä¸ª")
                                st.write(f"**å»ºè®®ä¿®å¤:** {issue.suggested_fix}")
                                
                                if len(issue.segment_ids) <= 10:
                                    st.write(f"**ç‰‡æ®µID:** {', '.join(issue.segment_ids)}")
            
            # Segment scores
            st.subheader("ğŸ“Š ç‰‡æ®µè¯„åˆ†")
            
            if report.segment_scores:
                # Create score distribution
                scores = list(report.segment_scores.values())
                
                fig = px.histogram(
                    x=scores,
                    nbins=20,
                    title="ç‰‡æ®µä¸€è‡´æ€§è¯„åˆ†åˆ†å¸ƒ",
                    labels={"x": "ä¸€è‡´æ€§è¯„åˆ†", "y": "ç‰‡æ®µæ•°é‡"}
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Show low-scoring segments
                low_scoring = [(seg_id, score) for seg_id, score in report.segment_scores.items() if score < 0.5]
                
                if low_scoring:
                    st.write(f"**ä½åˆ†ç‰‡æ®µ (< 0.5):** {len(low_scoring)} ä¸ª")
                    
                    low_scoring.sort(key=lambda x: x[1])  # Sort by score
                    
                    for seg_id, score in low_scoring[:10]:  # Show worst 10
                        st.write(f"- ç‰‡æ®µ {seg_id}: {score:.2f}")
            
            # Recommendations
            if report.recommendations:
                st.subheader("ğŸ’¡ æ”¹è¿›å»ºè®®")
                
                for i, rec in enumerate(report.recommendations, 1):
                    st.write(f"{i}. {rec}")
    
    def _render_emotion_trends(self, project_id: str):
        """Render emotion trends tab."""
        st.subheader("ğŸ“ˆ æƒ…æ„Ÿè¶‹åŠ¿åˆ†æ")
        
        analyses = self.analyzer.list_project_analyses(project_id)
        
        if len(analyses) < 2:
            st.info("éœ€è¦è‡³å°‘2æ¬¡åˆ†ææ‰èƒ½æ˜¾ç¤ºè¶‹åŠ¿")
            return
        
        # Consistency trend
        st.subheader("ğŸ”„ ä¸€è‡´æ€§è¶‹åŠ¿")
        
        dates = [analysis["created_at"][:10] for analysis in reversed(analyses)]
        consistency_scores = [analysis["overall_consistency"] for analysis in reversed(analyses)]
        
        fig = px.line(
            x=dates,
            y=consistency_scores,
            title="æƒ…æ„Ÿä¸€è‡´æ€§è¶‹åŠ¿",
            labels={"x": "æ—¥æœŸ", "y": "ä¸€è‡´æ€§è¯„åˆ†"},
            markers=True
        )
        fig.update_layout(yaxis_range=[0, 1])
        st.plotly_chart(fig, use_container_width=True)
        
        # Quality issues trend
        st.subheader("âš ï¸ è´¨é‡é—®é¢˜è¶‹åŠ¿")
        
        issue_counts = [analysis["quality_issues_count"] for analysis in reversed(analyses)]
        
        fig = px.bar(
            x=dates,
            y=issue_counts,
            title="è´¨é‡é—®é¢˜æ•°é‡è¶‹åŠ¿",
            labels={"x": "æ—¥æœŸ", "y": "é—®é¢˜æ•°é‡"}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Improvement suggestions based on trends
        st.subheader("ğŸ“Š è¶‹åŠ¿åˆ†æ")
        
        if len(consistency_scores) >= 3:
            recent_trend = consistency_scores[-3:]
            if all(recent_trend[i] <= recent_trend[i+1] for i in range(len(recent_trend)-1)):
                st.success("âœ… ä¸€è‡´æ€§è¯„åˆ†å‘ˆä¸Šå‡è¶‹åŠ¿ï¼")
            elif all(recent_trend[i] >= recent_trend[i+1] for i in range(len(recent_trend)-1)):
                st.warning("âš ï¸ ä¸€è‡´æ€§è¯„åˆ†å‘ˆä¸‹é™è¶‹åŠ¿ï¼Œéœ€è¦æ³¨æ„")
            else:
                st.info("â„¹ï¸ ä¸€è‡´æ€§è¯„åˆ†è¾ƒä¸ºç¨³å®š")
        
        # Best and worst analyses
        best_analysis = max(analyses, key=lambda x: x["overall_consistency"])
        worst_analysis = min(analyses, key=lambda x: x["overall_consistency"])
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.success(f"**æœ€ä½³åˆ†æ:** {best_analysis['analysis_id'][-8:]}")
            st.write(f"ä¸€è‡´æ€§: {best_analysis['overall_consistency']:.2f}")
            st.write(f"æ—¥æœŸ: {best_analysis['created_at'][:10]}")
        
        with col2:
            st.error(f"**æœ€å·®åˆ†æ:** {worst_analysis['analysis_id'][-8:]}")
            st.write(f"ä¸€è‡´æ€§: {worst_analysis['overall_consistency']:.2f}")
            st.write(f"æ—¥æœŸ: {worst_analysis['created_at'][:10]}")
    
    def _run_new_analysis(self, project_id: str):
        """Run a new emotion analysis."""
        st.info("æ–°çš„æƒ…æ„Ÿåˆ†æåŠŸèƒ½éœ€è¦é›†æˆåˆ°é¡¹ç›®å·¥ä½œæµä¸­")
        
        # This would typically integrate with the project management system
        # to get translation data and run analysis
        
        # Placeholder for now
        with st.form("analysis_config"):
            st.write("**åˆ†æé…ç½®**")
            
            source_lang = st.selectbox("æºè¯­è¨€", ["en", "zh", "ja", "ko", "fr", "de", "es"])
            target_lang = st.selectbox("ç›®æ ‡è¯­è¨€", ["zh-CN", "en", "ja", "ko", "fr", "de", "es"])
            
            analysis_name = st.text_input("åˆ†æåç§°", placeholder="å¯é€‰ï¼Œç”¨äºæ ‡è¯†æ­¤æ¬¡åˆ†æ")
            
            if st.form_submit_button("ğŸ­ å¼€å§‹åˆ†æ"):
                st.info("æ­¤åŠŸèƒ½éœ€è¦ä¸é¡¹ç›®ç®¡ç†ç³»ç»Ÿé›†æˆåæ‰èƒ½ä½¿ç”¨")
                # TODO: Integrate with project management to get actual translation data
                # translation_data = get_project_translation_data(project_id)
                # analysis = self.analyzer.analyze_project_emotions(
                #     project_id, translation_data, source_lang, target_lang
                # )
                # st.success(f"åˆ†æå®Œæˆï¼åˆ†æID: {analysis.analysis_id}")
                # st.rerun()