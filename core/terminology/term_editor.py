"""
æœ¯è¯­ç¼–è¾‘ç•Œé¢

ä¸ºStreamlitæä¾›æœ¯è¯­ç®¡ç†å’Œç¼–è¾‘çš„ç”¨æˆ·ç•Œé¢ç»„ä»¶
"""

import streamlit as st
import pandas as pd
from typing import Dict, List, Optional
from .term_manager import TermManager
from .term_extractor import extract_terms_from_translation
from .term_validator import TermValidator

def create_term_editor_interface():
    """åˆ›å»ºæœ¯è¯­ç¼–è¾‘å™¨ç•Œé¢"""
    st.header("ğŸ”§ ä¸“ä¸šåè¯ç®¡ç†")
    
    # åˆå§‹åŒ–æœ¯è¯­ç®¡ç†å™¨
    if 'term_manager' not in st.session_state:
        st.session_state.term_manager = TermManager()
    
    term_manager = st.session_state.term_manager
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“ æ‰‹åŠ¨ç®¡ç†", "ğŸ¤– è‡ªåŠ¨æå–", "ğŸ“Š ç»Ÿè®¡æŠ¥å‘Š", "ğŸ“¥ğŸ“¤ å¯¼å…¥å¯¼å‡º", "âš™ï¸ è®¾ç½®"
    ])
    
    with tab1:
        _manual_term_management(term_manager)
    
    with tab2:
        _auto_term_extraction(term_manager)
    
    with tab3:
        _statistics_report(term_manager)
    
    with tab4:
        _import_export_interface(term_manager)
    
    with tab5:
        _settings_interface(term_manager)

def _manual_term_management(term_manager: TermManager):
    """æ‰‹åŠ¨æœ¯è¯­ç®¡ç†ç•Œé¢"""
    st.subheader("æ‰‹åŠ¨æ·»åŠ /ç¼–è¾‘æœ¯è¯­")
    
    # æ·»åŠ æ–°æœ¯è¯­
    with st.expander("â• æ·»åŠ æ–°æœ¯è¯­", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            source_term = st.text_input("åŸæ–‡æœ¯è¯­", key="add_source")
            category = st.selectbox("åˆ†ç±»", 
                                  ["æŠ€æœ¯æœ¯è¯­", "äººå", "åœ°å", "å“ç‰Œ", "äº§å“", "å…¶ä»–"],
                                  key="add_category")
        
        with col2:
            target_term = st.text_input("ç¿»è¯‘æœ¯è¯­", key="add_target")
            priority = st.slider("ä¼˜å…ˆçº§", 1, 5, 1, key="add_priority")
        
        notes = st.text_area("å¤‡æ³¨", key="add_notes")
        
        if st.button("æ·»åŠ æœ¯è¯­", type="primary"):
            if source_term and target_term:
                success = term_manager.add_term(source_term, target_term, category, priority, notes)
                if success:
                    st.success("æœ¯è¯­æ·»åŠ æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.error("æœ¯è¯­æ·»åŠ å¤±è´¥")
            else:
                st.error("è¯·å¡«å†™åŸæ–‡æœ¯è¯­å’Œç¿»è¯‘æœ¯è¯­")
    
    # æ˜¾ç¤ºç°æœ‰æœ¯è¯­
    st.subheader("ç°æœ‰æœ¯è¯­åº“")
    
    all_terms = term_manager.get_all_terms()
    if not all_terms:
        st.info("æœ¯è¯­åº“ä¸ºç©ºï¼Œè¯·æ·»åŠ æœ¯è¯­æˆ–ä½¿ç”¨è‡ªåŠ¨æå–åŠŸèƒ½")
        return
    
    # æœç´¢å’Œè¿‡æ»¤
    col1, col2 = st.columns([2, 1])
    with col1:
        search_term = st.text_input("ğŸ” æœç´¢æœ¯è¯­", key="search_terms")
    with col2:
        filter_category = st.selectbox("ç­›é€‰åˆ†ç±»", 
                                     ["å…¨éƒ¨"] + term_manager.get_categories(),
                                     key="filter_category")
    
    # æ„å»ºæ˜¾ç¤ºæ•°æ®
    display_data = []
    for source, target in all_terms.items():
        category = term_manager.custom_terms["categories"].get(source, "general")
        priority = term_manager.custom_terms["priorities"].get(source, 1)
        notes = term_manager.custom_terms["notes"].get(source, "")
        
        # åº”ç”¨æœç´¢å’Œè¿‡æ»¤
        if search_term and search_term.lower() not in source.lower() and search_term.lower() not in target.lower():
            continue
        if filter_category != "å…¨éƒ¨" and category != filter_category:
            continue
        
        display_data.append({
            "åŸæ–‡": source,
            "ç¿»è¯‘": target,
            "åˆ†ç±»": category,
            "ä¼˜å…ˆçº§": priority,
            "å¤‡æ³¨": notes
        })
    
    if display_data:
        df = pd.DataFrame(display_data)
        
        # ä½¿ç”¨å¯ç¼–è¾‘çš„æ•°æ®è¡¨æ ¼
        edited_df = st.data_editor(
            df,
            use_container_width=True,
            num_rows="dynamic",
            column_config={
                "ä¼˜å…ˆçº§": st.column_config.SliderColumn(
                    "ä¼˜å…ˆçº§",
                    help="æœ¯è¯­ä¼˜å…ˆçº§ï¼ˆ1-5ï¼‰",
                    min_value=1,
                    max_value=5,
                    step=1,
                    format="%d"
                ),
                "åˆ†ç±»": st.column_config.SelectboxColumn(
                    "åˆ†ç±»",
                    help="æœ¯è¯­åˆ†ç±»",
                    options=["æŠ€æœ¯æœ¯è¯­", "äººå", "åœ°å", "å“ç‰Œ", "äº§å“", "å…¶ä»–"]
                )
            },
            key="term_editor"
        )
        
        # ä¿å­˜ä¿®æ”¹
        if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹"):
            _save_term_edits(term_manager, df, edited_df)
    else:
        st.info("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æœ¯è¯­")

def _auto_term_extraction(term_manager: TermManager):
    """è‡ªåŠ¨æœ¯è¯­æå–ç•Œé¢"""
    st.subheader("è‡ªåŠ¨æå–ä¸“ä¸šæœ¯è¯­")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘æ•°æ®
    source_file = "output/log/split_by_meaning.txt"
    target_file = "output/log/translated_chunks.txt"
    
    import os
    if not (os.path.exists(source_file) and os.path.exists(target_file)):
        st.warning("è¯·å…ˆå®Œæˆè§†é¢‘ç¿»è¯‘ï¼Œç„¶åå†ä½¿ç”¨è‡ªåŠ¨æå–åŠŸèƒ½")
        return
    
    if st.button("ğŸ¤– å¼€å§‹è‡ªåŠ¨æå–", type="primary"):
        with st.spinner("æ­£åœ¨æå–ä¸“ä¸šæœ¯è¯­..."):
            try:
                # è¯»å–ç¿»è¯‘æ•°æ®
                with open(source_file, 'r', encoding='utf-8') as f:
                    source_chunks = f.read().strip().split('\n')
                
                with open(target_file, 'r', encoding='utf-8') as f:
                    target_chunks = f.read().strip().split('\n')
                
                # æå–æœ¯è¯­
                extraction_result = extract_terms_from_translation(source_chunks, target_chunks)
                
                # ä¿å­˜æå–ç»“æœ
                term_manager.update_auto_extracted_terms(extraction_result)
                
                st.success("æœ¯è¯­æå–å®Œæˆï¼")
                st.rerun()
                
            except Exception as e:
                st.error(f"æå–å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºå»ºè®®çš„æœ¯è¯­
    suggested_terms = term_manager.get_suggested_terms()
    if suggested_terms:
        st.subheader("å»ºè®®çš„æœ¯è¯­å¯¹")
        
        for i, term_pair in enumerate(suggested_terms[:20]):  # åªæ˜¾ç¤ºå‰20ä¸ª
            col1, col2, col3, col4 = st.columns([2, 2, 1, 1])
            
            with col1:
                st.text(term_pair["source"])
            with col2:
                st.text(term_pair["target"])
            with col3:
                st.text(f"{term_pair['confidence']:.2f}")
            with col4:
                if st.button("æ·»åŠ ", key=f"add_suggested_{i}"):
                    success = term_manager.add_term(
                        term_pair["source"], 
                        term_pair["target"],
                        "è‡ªåŠ¨æå–"
                    )
                    if success:
                        st.success("å·²æ·»åŠ åˆ°æœ¯è¯­åº“")
                        st.rerun()

def _statistics_report(term_manager: TermManager):
    """ç»Ÿè®¡æŠ¥å‘Šç•Œé¢"""
    st.subheader("æœ¯è¯­åº“ç»Ÿè®¡")
    
    stats = term_manager.get_statistics()
    
    # åŸºæœ¬ç»Ÿè®¡
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("æ€»æœ¯è¯­æ•°", stats["total_terms"])
    with col2:
        st.metric("å»ºè®®æœ¯è¯­æ•°", stats["suggested_terms_count"])
    with col3:
        st.metric("è¿‘7å¤©ä¿®æ”¹", stats["recent_changes"])
    
    # åˆ†ç±»ç»Ÿè®¡
    if stats["categories"]:
        st.subheader("åˆ†ç±»åˆ†å¸ƒ")
        category_df = pd.DataFrame(
            list(stats["categories"].items()),
            columns=["åˆ†ç±»", "æ•°é‡"]
        )
        st.bar_chart(category_df.set_index("åˆ†ç±»"))
    
    # éªŒè¯æŠ¥å‘Š
    st.subheader("ä¸€è‡´æ€§æ£€æŸ¥")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¿»è¯‘æ•°æ®å¯ä»¥éªŒè¯
    target_file = "output/log/translated_chunks.txt"
    if os.path.exists(target_file):
        if st.button("ğŸ” è¿è¡Œä¸€è‡´æ€§æ£€æŸ¥"):
            with st.spinner("æ£€æŸ¥ä¸­..."):
                try:
                    with open(target_file, 'r', encoding='utf-8') as f:
                        target_chunks = f.read().strip().split('\n')
                    
                    validator = TermValidator(term_manager)
                    validation_result = validator.validate_terminology_consistency(target_chunks)
                    
                    if validation_result["inconsistencies"]:
                        st.warning(f"å‘ç° {len(validation_result['inconsistencies'])} ä¸ªä¸ä¸€è‡´çš„æœ¯è¯­")
                        for issue in validation_result["inconsistencies"]:
                            st.write(f"- **{issue['term']}**: æœŸæœ› '{issue['expected']}'ï¼Œä½†å‘ç° {issue['found_translations']}")
                    else:
                        st.success("æœ¯è¯­ä½¿ç”¨ä¸€è‡´ï¼")
                        
                except Exception as e:
                    st.error(f"æ£€æŸ¥å¤±è´¥: {e}")
    else:
        st.info("éœ€è¦ç¿»è¯‘æ•°æ®æ‰èƒ½è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥")

def _import_export_interface(term_manager: TermManager):
    """å¯¼å…¥å¯¼å‡ºç•Œé¢"""
    st.subheader("å¯¼å…¥/å¯¼å‡ºæœ¯è¯­åº“")
    
    # å¯¼å‡ºåŠŸèƒ½
    st.write("### ğŸ“¤ å¯¼å‡ºæœ¯è¯­åº“")
    if st.button("å¯¼å‡ºä¸ºExcel", type="primary"):
        export_path = "output/terminology/exported_terms.xlsx"
        success = term_manager.export_to_excel(export_path)
        if success:
            st.success(f"å¯¼å‡ºæˆåŠŸ: {export_path}")
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(export_path, "rb") as file:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½Excelæ–‡ä»¶",
                    data=file.read(),
                    file_name="terminology.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        else:
            st.error("å¯¼å‡ºå¤±è´¥")
    
    # å¯¼å…¥åŠŸèƒ½
    st.write("### ğŸ“¥ å¯¼å…¥æœ¯è¯­åº“")
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=['xlsx', 'xls'])
    
    if uploaded_file:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name
        
        # é¢„è§ˆæ–‡ä»¶å†…å®¹
        try:
            preview_df = pd.read_excel(tmp_path)
            st.write("æ–‡ä»¶é¢„è§ˆ:")
            st.dataframe(preview_df.head())
            
            if st.button("ç¡®è®¤å¯¼å…¥"):
                success = term_manager.import_from_excel(tmp_path)
                if success:
                    st.success("å¯¼å…¥æˆåŠŸï¼")
                    st.rerun()
                else:
                    st.error("å¯¼å…¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_path)

def _settings_interface(term_manager: TermManager):
    """è®¾ç½®ç•Œé¢"""
    st.subheader("æœ¯è¯­ç®¡ç†è®¾ç½®")
    
    # æ¸…ç†é€‰é¡¹
    st.write("### ğŸ§¹ æ•°æ®æ¸…ç†")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("æ¸…ç©ºè‡ªåŠ¨æå–çš„æœ¯è¯­", type="secondary"):
            if st.confirm("ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰è‡ªåŠ¨æå–çš„æœ¯è¯­å—ï¼Ÿ"):
                term_manager.auto_terms = {
                    "version": "1.0",
                    "extracted_at": "",
                    "suggested_pairs": [],
                    "term_frequency": {},
                    "important_terms": []
                }
                term_manager._save_auto_terms()
                st.success("è‡ªåŠ¨æå–æœ¯è¯­å·²æ¸…ç©º")
                st.rerun()
    
    with col2:
        if st.button("æ¸…ç©ºæœ¯è¯­å†å²", type="secondary"):
            if st.confirm("ç¡®å®šè¦æ¸…ç©ºæœ¯è¯­ä¿®æ”¹å†å²å—ï¼Ÿ"):
                term_manager.term_history = []
                term_manager._save_term_history()
                st.success("æœ¯è¯­å†å²å·²æ¸…ç©º")
                st.rerun()
    
    # æ˜¾ç¤ºå†å²è®°å½•
    if term_manager.term_history:
        st.write("### ğŸ“‹ æœ€è¿‘ä¿®æ”¹å†å²")
        recent_history = term_manager.term_history[-10:]  # æ˜¾ç¤ºæœ€è¿‘10æ¡
        for record in reversed(recent_history):
            timestamp = record["timestamp"][:19].replace('T', ' ')
            action = record["action"]
            term = record["source_term"]
            st.text(f"{timestamp} - {action}: {term}")

def _save_term_edits(term_manager: TermManager, original_df: pd.DataFrame, edited_df: pd.DataFrame):
    """ä¿å­˜æœ¯è¯­ç¼–è¾‘"""
    try:
        changes_made = False
        
        # æ¯”è¾ƒæ•°æ®æ¡†çš„å˜åŒ–
        for idx, (orig_row, edit_row) in enumerate(zip(original_df.itertuples(), edited_df.itertuples())):
            orig_source = orig_row.åŸæ–‡
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
            if (orig_row.ç¿»è¯‘ != edit_row.ç¿»è¯‘ or 
                orig_row.åˆ†ç±» != edit_row.åˆ†ç±» or 
                orig_row.ä¼˜å…ˆçº§ != edit_row.ä¼˜å…ˆçº§ or 
                orig_row.å¤‡æ³¨ != edit_row.å¤‡æ³¨):
                
                # æ›´æ–°æœ¯è¯­
                term_manager.update_term(
                    orig_source,
                    edit_row.ç¿»è¯‘,
                    edit_row.åˆ†ç±»,
                    edit_row.ä¼˜å…ˆçº§,
                    edit_row.å¤‡æ³¨
                )
                changes_made = True
        
        if changes_made:
            st.success("ä¿®æ”¹å·²ä¿å­˜ï¼")
            st.rerun()
        else:
            st.info("æ²¡æœ‰æ£€æµ‹åˆ°ä¿®æ”¹")
            
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥: {e}")