"""
Batch Processing Dashboard Module

Provides Streamlit UI for batch video processing management.
"""

import json
import os
from datetime import datetime
from typing import List, Dict, Any, Optional

try:
    import streamlit as st
    import plotly.express as px
    import plotly.graph_objects as go
    import pandas as pd
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False

from .batch_manager import BatchManager
from .task_queue import TaskStatus, TaskPriority

class BatchProcessingDashboard:
    """Streamlit dashboard for batch processing."""
    
    def __init__(self):
        if not STREAMLIT_AVAILABLE:
            raise ImportError("Streamlit and plotting libraries are required for the batch processing dashboard")
        
        self.batch_manager = BatchManager()
    
    def render_dashboard(self):
        """Render the complete batch processing dashboard."""
        
        st.title("ðŸŽ¬ æ‰¹é‡è§†é¢‘å¤„ç†")
        
        # Main tabs
        tab1, tab2, tab3, tab4, tab5 = st.tabs([
            "ðŸ“‹ ä»»åŠ¡æ¦‚è§ˆ",
            "âž• åˆ›å»ºæ‰¹é‡ä»»åŠ¡", 
            "ðŸ“Š é¡¹ç›®ç®¡ç†",
            "âš™ï¸ ç³»ç»Ÿç›‘æŽ§",
            "ðŸ“ˆ ç»Ÿè®¡æŠ¥å‘Š"
        ])
        
        with tab1:
            self._render_task_overview()
        
        with tab2:
            self._render_create_batch()
        
        with tab3:
            self._render_project_management()
        
        with tab4:
            self._render_system_monitoring()
        
        with tab5:
            self._render_statistics()
    
    def _render_task_overview(self):
        """Render task overview tab."""
        st.subheader("ðŸ“‹ ä»»åŠ¡é˜Ÿåˆ—æ¦‚è§ˆ")
        
        # Control buttons
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("â–¶ï¸ å¯åŠ¨å¤„ç†ç³»ç»Ÿ"):
                self.batch_manager.start_processing()
                st.success("å¤„ç†ç³»ç»Ÿå·²å¯åŠ¨")
                st.rerun()
        
        with col2:
            if st.button("â¹ï¸ åœæ­¢å¤„ç†ç³»ç»Ÿ"):
                self.batch_manager.stop_processing()
                st.success("å¤„ç†ç³»ç»Ÿå·²åœæ­¢")
                st.rerun()
        
        with col3:
            if st.button("ðŸ”„ åˆ·æ–°çŠ¶æ€"):
                st.rerun()
        
        # System status
        system_status = self.batch_manager.get_system_status()
        
        # Key metrics
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            status_text = "ðŸŸ¢ è¿è¡Œä¸­" if system_status["batch_processing_active"] else "ðŸ”´ å·²åœæ­¢"
            st.metric("ç³»ç»ŸçŠ¶æ€", status_text)
        
        with col2:
            scheduler_stats = system_status["scheduler_statistics"]
            st.metric("æ´»è·ƒå·¥ä½œçº¿ç¨‹", f"{scheduler_stats['busy_workers']}/{scheduler_stats['total_workers']}")
        
        with col3:
            queue_stats = system_status["queue_statistics"]
            running_tasks = queue_stats["by_status"].get("running", 0)
            pending_tasks = queue_stats["by_status"].get("pending", 0) + queue_stats["by_status"].get("queued", 0)
            st.metric("é˜Ÿåˆ—ä»»åŠ¡", f"{running_tasks}è¿è¡Œ / {pending_tasks}ç­‰å¾…")
        
        with col4:
            st.metric("é¡¹ç›®æ€»æ•°", system_status["total_projects"])
        
        # Recent tasks
        st.subheader("ðŸ•’ æœ€è¿‘ä»»åŠ¡")
        
        all_tasks = self.batch_manager.task_queue.list_tasks()
        recent_tasks = all_tasks[:10]  # Show last 10 tasks
        
        if recent_tasks:
            task_data = []
            for task in recent_tasks:
                task_data.append({
                    "ä»»åŠ¡ID": task.task_id[:8],
                    "ç±»åž‹": task.task_type,
                    "é¡¹ç›®": task.project_id,
                    "è¾“å…¥æ–‡ä»¶": os.path.basename(task.input_file),
                    "çŠ¶æ€": task.status.value,
                    "è¿›åº¦": f"{task.progress_percentage:.1f}%",
                    "åˆ›å»ºæ—¶é—´": task.created_at[:19]
                })
            
            df = pd.DataFrame(task_data)
            st.dataframe(df, use_container_width=True)
        else:
            st.info("æš‚æ— ä»»åŠ¡")
        
        # Task status distribution
        if queue_stats["total_tasks"] > 0:
            st.subheader("ðŸ“Š ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ")
            
            status_data = queue_stats["by_status"]
            
            # Create pie chart
            labels = list(status_data.keys())
            values = list(status_data.values())
            
            fig = px.pie(
                values=values,
                names=labels,
                title="ä»»åŠ¡çŠ¶æ€åˆ†å¸ƒ"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def _render_create_batch(self):
        """Render create batch tab."""
        st.subheader("âž• åˆ›å»ºæ‰¹é‡å¤„ç†ä»»åŠ¡")
        
        # Processing type selection
        processing_type = st.selectbox(
            "å¤„ç†ç±»åž‹",
            ["video_translation", "audio_extraction", "subtitle_generation", "video_transcoding"],
            format_func=lambda x: {
                "video_translation": "ðŸŽ¬ è§†é¢‘ç¿»è¯‘",
                "audio_extraction": "ðŸŽµ éŸ³é¢‘æå–",
                "subtitle_generation": "ðŸ“ å­—å¹•ç”Ÿæˆ",
                "video_transcoding": "ðŸŽžï¸ è§†é¢‘è½¬ç "
            }.get(x, x)
        )
        
        # File upload
        st.subheader("ðŸ“ é€‰æ‹©è§†é¢‘æ–‡ä»¶")
        uploaded_files = st.file_uploader(
            "ä¸Šä¼ è§†é¢‘æ–‡ä»¶",
            type=['mp4', 'avi', 'mov', 'mkv', 'wmv'],
            accept_multiple_files=True
        )
        
        # Or input file paths
        st.write("**æˆ–è€…è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰:**")
        file_paths_text = st.text_area(
            "æ–‡ä»¶è·¯å¾„",
            placeholder="/path/to/video1.mp4\n/path/to/video2.mp4",
            height=100
        )
        
        # Output configuration
        col1, col2 = st.columns(2)
        
        with col1:
            output_dir = st.text_input(
                "è¾“å‡ºç›®å½•",
                value="./batch_output",
                help="å¤„ç†åŽçš„æ–‡ä»¶å°†ä¿å­˜åˆ°æ­¤ç›®å½•"
            )
            
            project_id = st.text_input(
                "é¡¹ç›®IDï¼ˆå¯é€‰ï¼‰",
                placeholder="ç•™ç©ºè‡ªåŠ¨ç”Ÿæˆ",
                help="ç”¨äºŽç»„ç»‡å’Œè·Ÿè¸ªæ‰¹é‡ä»»åŠ¡"
            )
        
        with col2:
            priority = st.selectbox(
                "ä»»åŠ¡ä¼˜å…ˆçº§",
                [TaskPriority.LOW, TaskPriority.NORMAL, TaskPriority.HIGH, TaskPriority.CRITICAL],
                index=1,
                format_func=lambda x: {
                    TaskPriority.LOW: "ðŸŸ¢ ä½Ž",
                    TaskPriority.NORMAL: "ðŸŸ¡ æ™®é€š",
                    TaskPriority.HIGH: "ðŸŸ  é«˜",
                    TaskPriority.CRITICAL: "ðŸ”´ ç´§æ€¥"
                }[x]
            )
            
            tags_input = st.text_input(
                "æ ‡ç­¾ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰",
                placeholder="æ ‡ç­¾1, æ ‡ç­¾2"
            )
        
        # Processing configuration
        st.subheader("âš™ï¸ å¤„ç†é…ç½®")
        
        config_override = {}
        
        if processing_type == "video_translation":
            col1, col2 = st.columns(2)
            
            with col1:
                source_lang = st.selectbox("æºè¯­è¨€", ["en", "zh", "ja", "ko", "fr", "de", "es"])
                target_lang = st.selectbox("ç›®æ ‡è¯­è¨€", ["zh-CN", "en", "ja", "ko", "fr", "de", "es"])
                whisper_model = st.selectbox("Whisperæ¨¡åž‹", ["large-v3", "large-v3-turbo", "medium"])
            
            with col2:
                llm_model = st.selectbox("LLMæ¨¡åž‹", ["gpt-4", "claude-3-5-sonnet", "deepseek-v3"])
                tts_method = st.selectbox("TTSæ–¹æ³•", ["azure_tts", "openai_tts", "edge_tts"])
                burn_subtitles = st.checkbox("çƒ§å½•å­—å¹•", value=True)
            
            config_override = {
                "source_language": source_lang,
                "target_language": target_lang,
                "whisper_model": whisper_model,
                "llm_model": llm_model,
                "tts_method": tts_method,
                "burn_subtitles": burn_subtitles
            }
        
        elif processing_type == "audio_extraction":
            col1, col2 = st.columns(2)
            
            with col1:
                audio_format = st.selectbox("éŸ³é¢‘æ ¼å¼", ["wav", "mp3", "flac"])
                sample_rate = st.selectbox("é‡‡æ ·çŽ‡", [16000, 22050, 44100, 48000])
            
            with col2:
                channels = st.selectbox("å£°é“æ•°", [1, 2])
            
            config_override = {
                "format": audio_format,
                "sample_rate": sample_rate,
                "channels": channels
            }
        
        # Pipeline mode
        st.subheader("ðŸ”„ æµæ°´çº¿æ¨¡å¼")
        use_pipeline = st.checkbox("å¯ç”¨æµæ°´çº¿å¤„ç†", help="æŒ‰é¡ºåºæ‰§è¡Œå¤šä¸ªå¤„ç†æ­¥éª¤")
        
        pipeline_stages = []
        if use_pipeline:
            available_stages = ["audio_extraction", "video_translation", "subtitle_generation", "video_transcoding"]
            selected_stages = st.multiselect("é€‰æ‹©å¤„ç†æ­¥éª¤", available_stages)
            pipeline_stages = selected_stages
        
        # Submit button
        if st.button("ðŸš€ å¼€å§‹æ‰¹é‡å¤„ç†", type="primary"):
            # Collect video files
            video_files = []
            
            # From uploaded files
            if uploaded_files:
                # Save uploaded files temporarily
                temp_dir = "./temp_uploads"
                os.makedirs(temp_dir, exist_ok=True)
                
                for uploaded_file in uploaded_files:
                    temp_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(temp_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    video_files.append(temp_path)
            
            # From file paths
            if file_paths_text.strip():
                paths = [p.strip() for p in file_paths_text.strip().split('\n') if p.strip()]
                video_files.extend(paths)
            
            if not video_files:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªè§†é¢‘æ–‡ä»¶")
            else:
                tags = [tag.strip() for tag in tags_input.split(',') if tag.strip()] if tags_input else []
                
                try:
                    if use_pipeline and pipeline_stages:
                        # Pipeline processing
                        task_ids = self.batch_manager.add_pipeline_batch(
                            video_files=video_files,
                            output_directory=output_dir,
                            pipeline_stages=pipeline_stages,
                            project_id=project_id if project_id else None,
                            priority=priority
                        )
                        
                        total_tasks = sum(len(stage_tasks) for stage_tasks in task_ids.values())
                        st.success(f"âœ… æˆåŠŸåˆ›å»ºæµæ°´çº¿æ‰¹é‡ä»»åŠ¡ï¼")
                        st.info(f"ðŸ“Š å…±åˆ›å»º {total_tasks} ä¸ªä»»åŠ¡ï¼Œåˆ†å¸ƒåœ¨ {len(pipeline_stages)} ä¸ªå¤„ç†é˜¶æ®µ")
                        
                        # Show stage breakdown
                        for stage, stage_task_ids in task_ids.items():
                            st.write(f"**{stage}:** {len(stage_task_ids)} ä¸ªä»»åŠ¡")
                    
                    else:
                        # Single type processing
                        task_ids = self.batch_manager.add_video_batch(
                            video_files=video_files,
                            output_directory=output_dir,
                            project_id=project_id if project_id else None,
                            processing_type=processing_type,
                            config_override=config_override,
                            priority=priority,
                            tags=tags
                        )
                        
                        st.success(f"âœ… æˆåŠŸåˆ›å»ºæ‰¹é‡ä»»åŠ¡ï¼")
                        st.info(f"ðŸ“Š å…±æ·»åŠ  {len(task_ids)} ä¸ªä»»åŠ¡åˆ°å¤„ç†é˜Ÿåˆ—")
                    
                    # Start processing if not already running
                    system_status = self.batch_manager.get_system_status()
                    if not system_status["batch_processing_active"]:
                        if st.button("ðŸš€ å¯åŠ¨å¤„ç†ç³»ç»Ÿ"):
                            self.batch_manager.start_processing()
                            st.success("å¤„ç†ç³»ç»Ÿå·²å¯åŠ¨")
                    
                    st.rerun()
                
                except Exception as e:
                    st.error(f"åˆ›å»ºæ‰¹é‡ä»»åŠ¡å¤±è´¥: {e}")
    
    def _render_project_management(self):
        """Render project management tab."""
        st.subheader("ðŸ“Š é¡¹ç›®ç®¡ç†")
        
        # List all projects
        projects = self.batch_manager.list_batch_projects()
        
        if not projects:
            st.info("æš‚æ— æ‰¹é‡å¤„ç†é¡¹ç›®")
            return
        
        # Project list
        for project in projects:
            with st.expander(f"ðŸ“ {project['project_id']} - {project['completion_rate']:.1f}% å®Œæˆ"):
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("æ€»ä»»åŠ¡æ•°", project['task_count'])
                    st.metric("å·²å®Œæˆ", project['completed_count'])
                
                with col2:
                    st.metric("å¤±è´¥æ•°", project['failed_count'])
                    st.metric("è¿è¡Œä¸­", project['running_count'])
                
                with col3:
                    st.metric("å®ŒæˆçŽ‡", f"{project['completion_rate']:.1f}%")
                    st.write(f"**ä»»åŠ¡ç±»åž‹:** {', '.join(project['task_types'])}")
                
                with col4:
                    st.write(f"**åˆ›å»ºæ—¶é—´:** {project['created_at'][:19]}")
                
                # Project actions
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    if st.button("ðŸ“‹ æŸ¥çœ‹è¯¦æƒ…", key=f"details_{project['project_id']}"):
                        self._show_project_details(project['project_id'])
                
                with col2:
                    if st.button("ðŸ”„ é‡è¯•å¤±è´¥", key=f"retry_{project['project_id']}"):
                        retried = self.batch_manager.retry_failed_tasks(project['project_id'])
                        st.success(f"é‡è¯•äº† {retried} ä¸ªå¤±è´¥ä»»åŠ¡")
                        st.rerun()
                
                with col3:
                    if st.button("ðŸš« å–æ¶ˆé¡¹ç›®", key=f"cancel_{project['project_id']}"):
                        cancelled = self.batch_manager.cancel_batch(project['project_id'])
                        st.success(f"å–æ¶ˆäº† {cancelled} ä¸ªä»»åŠ¡")
                        st.rerun()
                
                with col4:
                    if st.button("ðŸ“Š å¯¼å‡ºæŠ¥å‘Š", key=f"export_{project['project_id']}"):
                        report = self.batch_manager.export_batch_report(project['project_id'])
                        
                        st.download_button(
                            label="ä¸‹è½½æŠ¥å‘Š",
                            data=json.dumps(report, ensure_ascii=False, indent=2),
                            file_name=f"batch_report_{project['project_id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            key=f"download_{project['project_id']}"
                        )
    
    def _render_system_monitoring(self):
        """Render system monitoring tab."""
        st.subheader("âš™ï¸ ç³»ç»Ÿç›‘æŽ§")
        
        # Real-time metrics
        system_status = self.batch_manager.get_system_status()
        scheduler_stats = system_status["scheduler_statistics"]
        
        # System resources
        st.subheader("ðŸ’» ç³»ç»Ÿèµ„æº")
        
        resources = scheduler_stats.get("system_resources", {})
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            cpu_usage = resources.get("cpu_percent", 0)
            st.metric("CPUä½¿ç”¨çŽ‡", f"{cpu_usage:.1f}%")
            st.progress(cpu_usage / 100)
        
        with col2:
            memory_usage = resources.get("memory_percent", 0)
            st.metric("å†…å­˜ä½¿ç”¨çŽ‡", f"{memory_usage:.1f}%")
            st.progress(memory_usage / 100)
        
        with col3:
            disk_usage = resources.get("disk_usage", 0)
            st.metric("ç£ç›˜ä½¿ç”¨çŽ‡", f"{disk_usage:.1f}%")
            st.progress(disk_usage / 100)
        
        # Worker status
        st.subheader("ðŸ‘· å·¥ä½œçº¿ç¨‹çŠ¶æ€")
        
        worker_status = self.batch_manager.scheduler.get_worker_status()
        
        if worker_status:
            worker_data = []
            for worker in worker_status:
                worker_data.append({
                    "å·¥ä½œçº¿ç¨‹ID": worker.worker_id,
                    "çŠ¶æ€": worker.status.value,
                    "å½“å‰ä»»åŠ¡": worker.current_task[:8] if worker.current_task else "æ— ",
                    "å·²å®Œæˆ": worker.tasks_completed,
                    "å¤±è´¥æ•°": worker.tasks_failed,
                    "æˆåŠŸçŽ‡": f"{worker.tasks_completed/(worker.tasks_completed+worker.tasks_failed)*100:.1f}%" if (worker.tasks_completed+worker.tasks_failed) > 0 else "N/A",
                    "æœ€åŽæ´»åŠ¨": worker.last_activity[:19]
                })
            
            df = pd.DataFrame(worker_data)
            st.dataframe(df, use_container_width=True)
        else:
            st.info("æ— æ´»è·ƒå·¥ä½œçº¿ç¨‹")
        
        # Queue statistics
        st.subheader("ðŸ“Š é˜Ÿåˆ—ç»Ÿè®¡")
        
        queue_stats = system_status["queue_statistics"]
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»ä»»åŠ¡æ•°", queue_stats["total_tasks"])
        
        with col2:
            st.metric("æˆåŠŸçŽ‡", f"{queue_stats.get('success_rate', 0):.1f}%")
        
        with col3:
            avg_exec_time = queue_stats.get("avg_execution_time", 0)
            st.metric("å¹³å‡æ‰§è¡Œæ—¶é—´", f"{avg_exec_time:.1f}åˆ†é’Ÿ")
        
        with col4:
            # Calculate throughput (tasks per hour)
            completed_tasks = queue_stats["by_status"].get("completed", 0)
            if avg_exec_time > 0:
                throughput = 60 / avg_exec_time  # tasks per hour
                st.metric("å¤„ç†åžåé‡", f"{throughput:.1f}ä»»åŠ¡/æ—¶")
            else:
                st.metric("å¤„ç†åžåé‡", "N/A")
    
    def _render_statistics(self):
        """Render statistics tab."""
        st.subheader("ðŸ“ˆ ç»Ÿè®¡æŠ¥å‘Š")
        
        # Time range selection
        col1, col2 = st.columns(2)
        
        with col1:
            time_range = st.selectbox(
                "ç»Ÿè®¡æ—¶é—´èŒƒå›´",
                ["ä»Šå¤©", "æœ¬å‘¨", "æœ¬æœˆ", "å…¨éƒ¨æ—¶é—´"],
                index=3
            )
        
        with col2:
            task_type_filter = st.selectbox(
                "ä»»åŠ¡ç±»åž‹ç­›é€‰",
                ["å…¨éƒ¨"] + ["video_translation", "audio_extraction", "subtitle_generation", "video_transcoding"]
            )
        
        # Get statistics
        all_tasks = self.batch_manager.task_queue.list_tasks()
        
        if task_type_filter != "å…¨éƒ¨":
            all_tasks = [t for t in all_tasks if t.task_type == task_type_filter]
        
        if not all_tasks:
            st.info("æš‚æ— ç»Ÿè®¡æ•°æ®")
            return
        
        # Task completion over time
        st.subheader("ðŸ“Š ä»»åŠ¡å®Œæˆè¶‹åŠ¿")
        
        completed_tasks = [t for t in all_tasks if t.status == TaskStatus.COMPLETED and t.completed_at]
        
        if completed_tasks:
            # Group by date
            completion_dates = {}
            for task in completed_tasks:
                date = task.completed_at[:10]  # YYYY-MM-DD
                completion_dates[date] = completion_dates.get(date, 0) + 1
            
            # Create time series chart
            dates = sorted(completion_dates.keys())
            counts = [completion_dates[date] for date in dates]
            
            fig = px.line(
                x=dates,
                y=counts,
                title="æ¯æ—¥ä»»åŠ¡å®Œæˆæ•°é‡",
                labels={"x": "æ—¥æœŸ", "y": "å®Œæˆä»»åŠ¡æ•°"}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Processing time analysis
        st.subheader("â±ï¸ å¤„ç†æ—¶é—´åˆ†æž")
        
        tasks_with_duration = [t for t in completed_tasks if t.actual_duration]
        
        if tasks_with_duration:
            durations = [t.actual_duration for t in tasks_with_duration]
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Duration histogram
                fig = px.histogram(
                    x=durations,
                    nbins=20,
                    title="å¤„ç†æ—¶é—´åˆ†å¸ƒ",
                    labels={"x": "å¤„ç†æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰", "y": "ä»»åŠ¡æ•°é‡"}
                )
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # Duration statistics
                avg_duration = sum(durations) / len(durations)
                min_duration = min(durations)
                max_duration = max(durations)
                
                st.metric("å¹³å‡å¤„ç†æ—¶é—´", f"{avg_duration:.1f} åˆ†é’Ÿ")
                st.metric("æœ€çŸ­å¤„ç†æ—¶é—´", f"{min_duration:.1f} åˆ†é’Ÿ")
                st.metric("æœ€é•¿å¤„ç†æ—¶é—´", f"{max_duration:.1f} åˆ†é’Ÿ")
        
        # Task type breakdown
        st.subheader("ðŸ“‹ ä»»åŠ¡ç±»åž‹åˆ†æž")
        
        type_counts = {}
        for task in all_tasks:
            task_type = task.task_type
            if task_type not in type_counts:
                type_counts[task_type] = {"total": 0, "completed": 0, "failed": 0}
            
            type_counts[task_type]["total"] += 1
            if task.status == TaskStatus.COMPLETED:
                type_counts[task_type]["completed"] += 1
            elif task.status == TaskStatus.FAILED:
                type_counts[task_type]["failed"] += 1
        
        # Create breakdown table
        breakdown_data = []
        for task_type, counts in type_counts.items():
            success_rate = (counts["completed"] / counts["total"] * 100) if counts["total"] > 0 else 0
            breakdown_data.append({
                "ä»»åŠ¡ç±»åž‹": task_type,
                "æ€»æ•°": counts["total"],
                "å·²å®Œæˆ": counts["completed"],
                "å¤±è´¥": counts["failed"],
                "æˆåŠŸçŽ‡": f"{success_rate:.1f}%"
            })
        
        df = pd.DataFrame(breakdown_data)
        st.dataframe(df, use_container_width=True)
    
    def _show_project_details(self, project_id: str):
        """Show detailed project information."""
        st.subheader(f"ðŸ“ é¡¹ç›®è¯¦æƒ…: {project_id}")
        
        batch_status = self.batch_manager.get_batch_status(project_id)
        
        if "error" in batch_status:
            st.error(batch_status["error"])
            return
        
        # Project summary
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»ä»»åŠ¡æ•°", batch_status["total_tasks"])
            st.metric("å·²å®Œæˆ", batch_status["completed"])
        
        with col2:
            st.metric("å¤±è´¥æ•°", batch_status["failed"])
            st.metric("è¿è¡Œä¸­", batch_status["running"])
        
        with col3:
            st.metric("ç­‰å¾…ä¸­", batch_status["pending"])
            st.metric("å®ŒæˆçŽ‡", f"{batch_status['completion_rate']:.1f}%")
        
        with col4:
            st.metric("å¤±è´¥çŽ‡", f"{batch_status['failure_rate']:.1f}%")
            remaining_time = batch_status["estimated_remaining_minutes"]
            if remaining_time > 60:
                time_text = f"{remaining_time//60:.1f}å°æ—¶"
            else:
                time_text = f"{remaining_time}åˆ†é’Ÿ"
            st.metric("é¢„è®¡å‰©ä½™æ—¶é—´", time_text)
        
        # Progress bar
        st.progress(batch_status["overall_progress"] / 100, text=f"æ€»ä½“è¿›åº¦: {batch_status['overall_progress']:.1f}%")
        
        # Task list
        st.subheader("ðŸ“‹ ä»»åŠ¡åˆ—è¡¨")
        
        task_data = []
        for task in batch_status["tasks"]:
            task_data.append({
                "ä»»åŠ¡ID": task["task_id"][:8],
                "ä»»åŠ¡ç±»åž‹": task["task_type"],
                "è¾“å…¥æ–‡ä»¶": task["input_file"],
                "çŠ¶æ€": task["status"],
                "è¿›åº¦": f"{task['progress']:.1f}%",
                "é”™è¯¯": task["error"][:50] + "..." if task["error"] and len(task["error"]) > 50 else task["error"] or ""
            })
        
        df = pd.DataFrame(task_data)
        st.dataframe(df, use_container_width=True)