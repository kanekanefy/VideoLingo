#!/usr/bin/env python3
"""
VideoLingoé›†æˆæµ‹è¯• - ä¸“ä¸šåè¯ç®¡ç†ç³»ç»Ÿ

æµ‹è¯•ä¸ç°æœ‰ç¿»è¯‘æµç¨‹çš„é›†æˆ
"""

import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def create_mock_translation_data():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„ç¿»è¯‘æ•°æ®"""
    
    # åˆ›å»ºå¿…è¦çš„è¾“å‡ºç›®å½•
    os.makedirs("output/log", exist_ok=True)
    
    # æ¨¡æ‹Ÿæºæ–‡æœ¬ï¼ˆåˆ†å¥åçš„æ–‡æœ¬ï¼‰
    source_chunks = [
        "Welcome to the world of artificial intelligence.",
        "Machine learning is a subset of AI that focuses on algorithms.",
        "OpenAI has developed ChatGPT using neural networks.",
        "Deep learning uses artificial neural networks with multiple layers.",
        "Natural language processing is another important AI field."
    ]
    
    # æ¨¡æ‹Ÿç¿»è¯‘æ–‡æœ¬ï¼ˆåˆå§‹ç¿»è¯‘ï¼Œæœ¯è¯­ä¸ä¸€è‡´ï¼‰
    target_chunks = [
        "æ¬¢è¿æ¥åˆ°artificial intelligenceçš„ä¸–ç•Œã€‚",
        "Machine learningæ˜¯AIçš„ä¸€ä¸ªå­é›†ï¼Œä¸“æ³¨äºç®—æ³•ã€‚", 
        "OpenAIä½¿ç”¨neural networkså¼€å‘äº†ChatGPTã€‚",
        "Deep learningä½¿ç”¨å¤šå±‚çš„artificial neural networksã€‚",
        "Natural language processingæ˜¯å¦ä¸€ä¸ªé‡è¦çš„AIé¢†åŸŸã€‚"
    ]
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("output/log/split_by_meaning.txt", 'w', encoding='utf-8') as f:
        f.write('\n'.join(source_chunks))
    
    with open("output/log/translated_chunks.txt", 'w', encoding='utf-8') as f:
        f.write('\n'.join(target_chunks))
    
    return source_chunks, target_chunks

def test_terminology_integration():
    """æµ‹è¯•æœ¯è¯­ç®¡ç†é›†æˆåŠŸèƒ½"""
    print("ğŸ”— æµ‹è¯•VideoLingoé›†æˆåŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        source_chunks, target_chunks = create_mock_translation_data()
        print("âœ… åˆ›å»ºæ¨¡æ‹Ÿç¿»è¯‘æ•°æ®æˆåŠŸ")
        
        # æµ‹è¯•æœ¯è¯­æå–å’Œåº”ç”¨çš„å®Œæ•´æµç¨‹
        print("\nğŸ“ æµ‹è¯•å®Œæ•´çš„æœ¯è¯­ç®¡ç†æµç¨‹...")
        
        # æ¨¡æ‹Ÿæœ¯è¯­ç®¡ç†æµç¨‹
        class IntegratedTermManager:
            def __init__(self):
                self.terms = {}
                self.applied_count = 0
            
            def extract_and_add_terms(self, source_texts, target_texts):
                """æ¨¡æ‹Ÿä»ç¿»è¯‘ä¸­æå–å’Œæ·»åŠ æœ¯è¯­"""
                # é¢„å®šä¹‰çš„æœ¯è¯­æ˜ å°„ï¼ˆæ¨¡æ‹Ÿè‡ªåŠ¨æå–çš„ç»“æœï¼‰
                suggested_terms = {
                    "artificial intelligence": "äººå·¥æ™ºèƒ½",
                    "AI": "äººå·¥æ™ºèƒ½", 
                    "machine learning": "æœºå™¨å­¦ä¹ ",
                    "ChatGPT": "ChatGPT",
                    "OpenAI": "OpenAI",
                    "neural networks": "ç¥ç»ç½‘ç»œ",
                    "artificial neural networks": "äººå·¥ç¥ç»ç½‘ç»œ",
                    "deep learning": "æ·±åº¦å­¦ä¹ ",
                    "natural language processing": "è‡ªç„¶è¯­è¨€å¤„ç†"
                }
                
                self.terms.update(suggested_terms)
                return len(suggested_terms)
            
            def apply_terms_to_translations(self, target_texts):
                """åº”ç”¨æœ¯è¯­åˆ°ç¿»è¯‘æ–‡æœ¬"""
                corrected_texts = []
                
                for text in target_texts:
                    corrected_text = text
                    applied_in_text = 0
                    
                    for source_term, target_term in self.terms.items():
                        if source_term in corrected_text:
                            corrected_text = corrected_text.replace(source_term, target_term)
                            applied_in_text += 1
                            self.applied_count += 1
                    
                    corrected_texts.append(corrected_text)
                
                return corrected_texts
            
            def get_statistics(self):
                return {
                    "total_terms": len(self.terms),
                    "applied_corrections": self.applied_count
                }
        
        # åˆ›å»ºé›†æˆç®¡ç†å™¨
        manager = IntegratedTermManager()
        
        # 1. æå–æœ¯è¯­
        extracted_count = manager.extract_and_add_terms(source_chunks, target_chunks)
        print(f"âœ… æå–æœ¯è¯­æ•°é‡: {extracted_count}")
        
        # 2. åº”ç”¨æœ¯è¯­
        corrected_chunks = manager.apply_terms_to_translations(target_chunks)
        print("âœ… åº”ç”¨æœ¯è¯­åˆ°ç¿»è¯‘æ–‡æœ¬")
        
        # 3. æ˜¾ç¤ºæ”¹è¿›ç»“æœ
        print("\nğŸ“Š ç¿»è¯‘æ”¹è¿›å¯¹æ¯”:")
        for i, (original, corrected) in enumerate(zip(target_chunks, corrected_chunks)):
            if original != corrected:
                print(f"\nå¥å­ {i+1}:")
                print(f"  åŸå§‹: {original}")
                print(f"  æ”¹è¿›: {corrected}")
        
        # 4. ç»Ÿè®¡ä¿¡æ¯
        stats = manager.get_statistics()
        print(f"\nğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æœ¯è¯­åº“å¤§å°: {stats['total_terms']}")
        print(f"  åº”ç”¨çš„ä¿®æ­£: {stats['applied_corrections']}")
        
        # 5. ä¿å­˜æ”¹è¿›åçš„ç¿»è¯‘
        with open("output/log/corrected_translations.txt", 'w', encoding='utf-8') as f:
            f.write('\n'.join(corrected_chunks))
        print("âœ… ä¿å­˜æ”¹è¿›åçš„ç¿»è¯‘æ–‡ä»¶")
        
        return True
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_streamlit_interface_mock():
    """æ¨¡æ‹Ÿæµ‹è¯•Streamlitç•Œé¢åŠŸèƒ½"""
    print("\nğŸ¨ æ¨¡æ‹Ÿæµ‹è¯•Streamlitç•Œé¢åŠŸèƒ½...")
    
    try:
        # æ¨¡æ‹Ÿç•Œé¢æ“ä½œ
        interface_operations = [
            "æ˜¾ç¤ºæœ¯è¯­ç®¡ç†æ ‡ç­¾é¡µ",
            "åŠ è½½ç°æœ‰æœ¯è¯­åº“", 
            "æ˜¾ç¤ºè‡ªåŠ¨æå–çš„æœ¯è¯­å»ºè®®",
            "ç”¨æˆ·æ‰‹åŠ¨æ·»åŠ æœ¯è¯­",
            "æ‰¹é‡ç¼–è¾‘æœ¯è¯­",
            "è¿è¡Œä¸€è‡´æ€§æ£€æŸ¥",
            "æ˜¾ç¤ºç»Ÿè®¡æŠ¥å‘Š",
            "è§¦å‘é‡æ–°ç¿»è¯‘"
        ]
        
        print("æ¨¡æ‹Ÿç”¨æˆ·ç•Œé¢æ“ä½œæµç¨‹:")
        for i, operation in enumerate(interface_operations, 1):
            print(f"  {i}. {operation} âœ…")
        
        # æ¨¡æ‹Ÿç•Œé¢çŠ¶æ€
        interface_state = {
            "current_tab": "æ‰‹åŠ¨ç®¡ç†",
            "loaded_terms": 9,
            "suggested_terms": 5,
            "validation_errors": 0,
            "last_operation": "é‡æ–°ç¿»è¯‘å®Œæˆ"
        }
        
        print(f"\nç•Œé¢çŠ¶æ€æ‘˜è¦:")
        for key, value in interface_state.items():
            print(f"  {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç•Œé¢æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\nğŸ” æµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
    
    test_cases = [
        {
            "name": "ç©ºæœ¯è¯­åº“",
            "terms": {},
            "text": "This is a test.",
            "expected_changes": 0
        },
        {
            "name": "é‡å¤æœ¯è¯­",
            "terms": {"AI": "äººå·¥æ™ºèƒ½"},
            "text": "AI and AI systems use AI technology.",
            "expected_changes": 3
        },
        {
            "name": "éƒ¨åˆ†åŒ¹é…",
            "terms": {"machine": "æœºå™¨"},
            "text": "Machine learning and machines are different.",
            "expected_changes": 1  # åªåŒ¹é…ç‹¬ç«‹çš„"machine"
        },
        {
            "name": "å¤§å°å†™æ•æ„Ÿ",
            "terms": {"api": "æ¥å£"},
            "text": "Use the API for integration.",
            "expected_changes": 0  # ä¸åº”è¯¥åŒ¹é…
        }
    ]
    
    passed_cases = 0
    
    for case in test_cases:
        try:
            # ç®€å•çš„æœ¯è¯­åº”ç”¨å‡½æ•°
            def apply_terms_simple(text, terms):
                result = text
                changes = 0
                for source, target in terms.items():
                    original_count = result.count(source)
                    result = result.replace(source, target)
                    changes += original_count
                return result, changes
            
            result_text, actual_changes = apply_terms_simple(case["text"], case["terms"])
            
            if actual_changes == case["expected_changes"]:
                print(f"  âœ… {case['name']}: é¢„æœŸ {case['expected_changes']} æ¬¡ä¿®æ”¹ï¼Œå®é™… {actual_changes} æ¬¡")
                passed_cases += 1
            else:
                print(f"  âŒ {case['name']}: é¢„æœŸ {case['expected_changes']} æ¬¡ä¿®æ”¹ï¼Œå®é™… {actual_changes} æ¬¡")
                
        except Exception as e:
            print(f"  âŒ {case['name']}: æµ‹è¯•å¼‚å¸¸ - {e}")
    
    print(f"\nè¾¹ç•Œæµ‹è¯•ç»“æœ: {passed_cases}/{len(test_cases)} é€šè¿‡")
    return passed_cases == len(test_cases)

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª VideoLingo ä¸“ä¸šåè¯ç®¡ç†ç³»ç»Ÿ - é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("æœ¯è¯­ç®¡ç†é›†æˆ", test_terminology_integration),
        ("ç•Œé¢åŠŸèƒ½æ¨¡æ‹Ÿ", test_streamlit_interface_mock), 
        ("è¾¹ç•Œæƒ…å†µæµ‹è¯•", test_edge_cases)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ”¬ è¿è¡Œæµ‹è¯•: {test_name}")
        print("-" * 40)
        
        if test_func():
            passed += 1
            print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
        else:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
    
    print("\n" + "=" * 60)
    print(f"ğŸ† é›†æˆæµ‹è¯•ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ ä¸“ä¸šåè¯ç®¡ç†ç³»ç»Ÿé›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
        print("\nğŸš€ ç³»ç»Ÿå°±ç»ªçŠ¶æ€:")
        print("  âœ… æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸")
        print("  âœ… æœ¯è¯­æå–å·¥ä½œ")
        print("  âœ… ç¿»è¯‘é›†æˆæˆåŠŸ")
        print("  âœ… è¾¹ç•Œæƒ…å†µå¤„ç†")
        print("  âœ… ç•Œé¢é€»è¾‘æ­£ç¡®")
        
        print("\nğŸ“‹ éƒ¨ç½²æ¸…å•:")
        print("  1. âœ… æ¨¡å—æ–‡ä»¶å·²åˆ›å»º")
        print("  2. âœ… ç¿»è¯‘æµç¨‹å·²é›†æˆ") 
        print("  3. âœ… Streamlitç•Œé¢å·²å‡†å¤‡")
        print("  4. âœ… æµ‹è¯•ç”¨ä¾‹å·²éªŒè¯")
        print("  5. â³ ç­‰å¾…å®Œæ•´ç¯å¢ƒæµ‹è¯•")
        
        return True
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤åå†éƒ¨ç½²ã€‚")
        return False

if __name__ == "__main__":
    main()